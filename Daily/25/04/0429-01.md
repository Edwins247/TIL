## TIL

### CPU 스케줄링
- CPU 스케줄링은 운영체제가 여러 개의 READY 상태 프로세스(또는 스레드)중에서 어떤 것을 CPU에 할당해서 실행시킬지를 결정하는 전략을 말함(즉, 어떤 프로세스 or 스레드 CPU를 먼저 사용할지 결정하는 알고리즘과 정책)
- CPU 스케줄링의 필요성
  - CPU는 자원이 한정적, 멀티코어라도 수십 개의 프로세스를 동시에 실행할 수 없음
  - 사용자 반응 속도 향상, 대기 시간을 줄이고 응답을 빠르게
  - 공정한 자원 분배, 한 작업이 너무 오래 점유하지 않도록
  - 시스템 효율 향상, CPU가 놀지 않도록 I/O 작업과 병행해서 처리

#### 프로세스의 우선순위
- 운영체제는 모든 프로세스를 동일하게 취급하지 않고, 우선순위(Priority)를 기반으로 어떤 프로세스를 먼저 실행할지 결정함(우선순위가 높을수록 CPU를 더 빨리, 더 자주 할당 받음)
- I/O 중심 프로세스: 대부분의 시간동안 입출력 작업을 수행
- CPU 중심 프로세스: 대부분의 시간을 연산, 계산, 반복 등의 작업을 수행
- 대화형 프로세스: 사용자 입력과 즉시 반응이 필요한 프로그램
- 배치 프로세스: 자동화된 작업 또는 스케줄된 작업
- 실시간 프로세스: 정해진 시간 안에 반드시 실행되어야 함
- 시스템 프로세스: 운영체제가 직접 실행하는 핵심 프로세스

#### 입출력과 CPU 집중 프로세스
- I/O 집중 프로세스(I/O-bound)
  - CPU는 잠깐 쓰고, 곧 I/O 대기 상태로 빠짐ㅁ
  - 응답 속도 중시, 빠르게 실행되고 대기 상태로 넘어가야 시스템 효율 증가
  - 실행 상태보다는 입출력을 위한 대기 상태에 더 많이 머무르게 됨
  - 예시. 비디오 재생, 디스크 백업, 웹 서버, 로그 수집기, DB 클라이언트
- CPU 집중 프로세스(CPU-bound)
  - I/O는 거의 없고, 연속적으로 CPU 점유
  - 대기 상태보다는 실행 상태에 더 많이 머무리게 됨
  - 예시. 이미지/영상 처리, 과학 시뮬레이션, AI 학습, 대규모 연산
- 어떤 프로세스를 먼저 실행하는 것이 유리할까?
  - I/O 프로세스를 먼저 실행시키는 것이 효율적
  - I/O 프로세스는 CPU를 잠깐만 사용하고 대부분 대기 상태에 머무름
  - 빨리 실행시켜서 I/O 작업을 시작하게 만들면, 그 동안은 CPU는 다른 프로세스에 할당 가능
  - 따라서 CPU와 I/O 자원을 동시에 효율적으로 활용할 수 있음
  - 만약 반대로 하게 되면?
    - CPU를 오래 점유 -> I/O 프로세스는 ready 상태에서 계속 기다림
    - I/O 작업이 지연됨 -> 사용자 응답이 느려짐
    - CPU는 계속 사용되지만 입출력 장치는 활용되고 있지 않음

#### 스케줄링 큐(Scheduling Queue)
- 운영체제가 현재 실행 대기 중인 프로세스들을 분류해서 저장해두는 공간
- 프로세스를 상태에 따라 관리하기 위해 사용하는 줄
- 스케줄링 큐를 사용하는 이유는 매번 CPU가 다음에 실행할 프로세스를 찾기 위해 모든 프로세스를 보는 것은 비효율적이기 때문
- 프로세스의 현재 상태는(Running, Ready, Waiting 등)에 따라 다르게 구성됨
- 스케줄러가 CPU 할당 대상을 고를 때 효율적
- 우선순위, 정책에 따라 큐를 계층적으로 나눌 수 있음
- 대표적인 스케줄링 큐
  - Job Queue: 시스템에 들어온 모든 작업이 처음 들어가는 큐
  - Ready Queue: 메모리에 올라와서 실행 대기 중인 프로세스들이 대기하는 큐(흔히 말하는 스케줄링 대상 큐)
  - Device Queue: I/O 작업을 기다리는 프로세스들이 대기
  - Waiting Queue: 이벤트가 발생하길 기다리는 상태(입출력 완료, 타이머, 인터럽트 등)
  - Terminated List: 종료된 프로세스가 정리되기 전 잠시 머무르는 공간

#### 스케줄링 큐와 우선순위
- 만약 스케줄링 큐에 프로세스들이 순서대로 줄을 서 있고, 그 와중에 우선순위가 높은 작업이 새로 들어오면 어떻게 될까? => 운영 체제가 어떤 정책을 따르냐에 따라 처리가 달라짐
- 비선점형(non-preemptive): 실행중인 프로세스가 끝날 때까지 기다림, 예측 가능성은 높지만 반응성이 낮음
- 선점형(preemptive): 현재 실행중인 프로세스를 중단하고, 우선순위가 높은 프로세스를 즉시 실행
  - 현재 실행 중이던 프로세스는 다시 Ready Queue로 이동, 사용자 체감 성능 향상, 실시간 시스템에 적합
- 대부분의 현대 운영체제는 선점형 기반으로 동작함(linux, windows, macOS 등)
- 비선점과 선점형 스케줄링 비교
  - 비선점형 스케줄링. 한 번 CPU를 할당받은 프로세스가 끝날때까지 CPU를 계속 점유
    - 다른 프로세스가 Ready 상태가 되어도 지금 실행 중인 프로세스가 끝날 때까지 기다림
    - 응답시간이 느림. 급한 작업이 와도 기다려야함
    - 컨텍스트 스위칭에서 발생하는 오버헤드가 선점형에 비해 적음
    - 과거의 단순한 시스템, 임베디드 시스템 일부가 이런 방식으로 동작함
  - 선점형 스케줄링. 실행 중인 프로세스가 있어도, 더 우선순위가 높은 프로세스가 오면 CPU를 뻇음
    - 즉각적인 반응 가능(실시간 요구 처리 가능)
    - 컨텍스트 스위칭이 자주 발생함 -> 오버헤드 증가
    - 현대 운영체제의 대부분이 선점형 기반

#### CPU 스케줄링 알고리즘
- 운영체제는 CPU라는 한정된 자원을 여러 프로세스에게 공정하고 효율적으로 나눠주기 위해 다양한 스케줄링 알고리즘을 사용함
- FCFS(First Come, First-Served)
  - 도착한 순서대로 CPU를 할당하는 방식
  - 마치 은행의 번호표처럼, 줄 선 순서대로 처리하는 가장 단순한 스케줄링 기법, Ready Queue에서 동작하는 방식
  - 먼저 도착한 프로세스가 먼저 실행되며 끝날 때까지 CPU를 점유함(비선점형), 새로 들어온 프로세스는 대기열 맨 뒤로 추가됨
  - FIFO 큐만 유지하면 되기 때문에 구현이 매우 간단하며 실행 순서가 명확하여 예측이 가능함
  - 긴 작업도 빠짐없이 수행되기 때문에 CPU 사용률이 향상됨 하지만 긴 작업 하나가 앞에 있으면 짧은 작업들이 오래 기다려야함(호위 효과, Convoy effect)
  - 작업 시간 편차가 클수록 평균 대기 시간이 커질 수 있음, 비선점형이기 떄문에 긴 작업이 시스템 반응성을 떨어뜨림
- SJF(Shortest Job First)
  - CPU 실행 시간이 가장 짧은 프로세스를 먼저 실행하는 비선점형 스케줄링 방식
  - 평균 대기 시간을 최소화할 수 있는 이론적으로는 최적의 알고리즘, 실행 시간이 얼마나 걸릴지 사전에 알아야 한다는 특징이 있음(일반적으로 어렵거나 부정확함)
  - 짧은 작업이 우선적으로 처리되는 장점이 있지만 긴 작업은 계속 뒤로 밀릴 수 있음
- Priority
  - 각 프로세스에 우선순위 값을 부여하고, 우선순위가 높은 프로세스부터 CPU를 할당하는 방식
  - 급한 작업을 빠르게 처리할 수 있음 -> 시스템/실시간 작업에 적합
  - 우선순위 설정으로 유연한 제어 가능 -> 서비스 등급 기반 처리 가능
  - 기아(starvation) 현상이 발생할 수 있음 -> 낮은 우선순위는 계속 뒤로 밀릴 수 있음 -> 기아 방지를 위해 Aging 기법을 사용함(시간이 지날수록 우선 순위를 자동으로 높임)
  - 선점, 비선점형으로 모두 동작할 수 있으며 선점형인 경우에는 컨텍스트 스위칭 비용 증가
- Round Robin
  - 각 프로세스에게 동일한 시간만큼 CPU를 할당하고, 시간이 끝나면 Ready Queue로 보내고, 다음 프로세스로 전환, 선점형 스케줄링
  - Time Quantum이 지나면 -> 컨텍스트 스위칭 발생 -> 만약 너무 짧은 시간을 설정하면 스위칭이 많이 발생하고, 너무 길면 FCFS처럼 동작
  - 짧은 응답 시간 보장, 공정성이 매우 높음 -> 모든 프로세스가 같은 기회를 가짐
  - 작업이 많을수록 길어짐. 따라서 평균 대기 시간이 길어질 수 있음, 실시간 사용자 환경에 적합함(서버, 게임 등)
- MLFQ
  - 여러 개의 Ready Queue를 계층적으로 운영하면서 프로세스의 행동 패턴(실행 시간, CPU 사용량)에 따라 다른 큐로 이동시키며 우선순위를 동적으로 조절하는 스케줄링 방식
  - 짧게 실행되는 프로세스 -> 높은 우선순위 큐에 계속 머물고
  - 오래 걸리는 프로세스 -> 점점 낮은 큐로 내려가게 됨
  - SJF의 효율성과 RR의 공정성을 조합한 구조
  - 동작 방식
    - 모든 새 프로세스는 최상위 큐에 배치됨
    - 주어진 time quantum안에 끝나면 -> 완료
    - 끝나지 않으면 -> 한 단계 아래 큐로 이동
    - 계속 반복 -> 가장 아래 단계의 큐에 도달하면 FCFS로 처리
    - 짧은 작업은 빠르게 끝내고, 긴 작업은 뒤로 미루면서도 실행 보장을 할 수 있음

-----

### 동기화와 병행성 제어
- 프로세스 동기화 = Process Synchronization
  - 동시에 실행되는 여러 프로세스(또는 스레드)가 공유 자원(Shared Resources)에 접근할 때, 충돌이나 데이터 손상 없이 일관성을 유지하도록 제어하는 것
  - 실행 순서를 제어하는 것과 상호 배제(동시에 접근해서는 안되는 자원에 하나의 프로세스만 접근)
- 상호 배제 = Mutual Exclusion
  - 여러 프로세스 또는 스레드가 공유 자원에 동시에 접근하지 못하도록 보장하는 것
  - 한 프로세스가 공유 자원을 사용하는 동안 다른 프로세스는 그 자원에 접근할 수 없도록 막는 규칙
- 동기화가 필요한 상황
  - 공유 메모리 접근: 여러 프로세스가 같은 변수, 버퍼, 캐시 등을 공유할 때
  - 파일, DB등 I/O 리소스: 동시에 접근하면 무결성 깨짐
  - 스레드 간 협력 작업: 순서 보장, 신호 주고받기 필요
- 생산자와 소비자 문제
  - 공유 버퍼(큐)를 기준으로 생산자(Producer)는 데이터를 생성해서 버퍼에 넣고 소비자(Consumer)는 데이터를 꺼내서 소비하는 상황에서 서로 충돌 없이 동작하도록 동기화하는 문제
  - 여기서 두 프로세스는 동시에 실행될 수 있고, 공유 자원은 고정 크기의 버퍼(Queue)하나뿐
  - 발생할 수 있는 문제
    - 버퍼가 가득 찼는데 생산자가 또 넣으려 한다면? => 오버플로우 위험
    - 버퍼가 비었는데 소비자가 꺼내려고 한다면? => 언더플로우 위험
    - 생산자와 소비자가 동시에 버퍼를 수정 => Race Condition 발생 위험
    - 이 문제를 해결하기 위해서는 상호 배제 + 조건 동기화가 필요함
- 공유 자원
  - 둘 이상의 프로세스나 스레드가 동시에 접근할 수 있는 자원, 하나의 자원에 동시 접근 시 충돌이 발생할 수 있음
  - 잘못된 결과나 예외, 교착상태 등을 유발함
  - 공유 자원의 종류
    - 변수, 배열: 전역 변수 등 / 파일: 로그 파일, 설정 파일 / 버퍼/큐: 생산자 - 소비자 큐 / 데이터베이스 커넥션: 다중 스레드 DB 접근
- 임계 구역
  - 동시에 실행하면 문제가 발생하는 자원에 접근하는 코드 영역을 임계 구역(critical section)이라고 함
  - 두 개 이상의 프로세스가 임계 구역에 접근하고자 하면 둘 중 하나는 대기해야함
  - 임계 구역을 보호할 수 있는 방법
    - 둘 이상의 프로세스가 공유 자원에 동시에 접근할 때, 올바르고 예측 가능한 결과를 보장하기 위한 제어 매커니즘
    - 뮤텍스 락(Mutex Lock), 세마포(Semaphore), 모니터(Monitor)
- 뮤텍스 락(Mutex Lock)
  -  상호 배제(mutual exclusion)를 위한 가장 기본적인 락
  -  한 순간에 단 하나의 스레드만 임계 구역에 진입할 수 있음, 락을 획득한 스레드는 반드시 해제해야함(lock -> unlock)
  -  락을 해제하지 않으면 데드락 발생할 수 있음(교착상태)
  -  하나의 스레드만 통과할 수 있으므로 단일 접근을 보장함, 빠르고 단순하기 때문에 오버헤드가 적음
- 세마포(Semaphore)
  - 정수형 카운터를 사용하여 동시에 접근 가능한 프로세스의 수를 제한하는 동기화 도구
  - 즉, N개의 자원이 있을 때 N명까지 접근을 허용하고, 그 이상은 대기시키는 방식
  - 뮤텍스와는 다르게 여러 개 허용 가능(동시 접근 허용)
  - 먼저 기다린 순서대로 처리되지 않을 수 있음(순서에 대한 보장이 없음)
  - 동시 최대 허용 수를 설정할 수 있음(카운팅 가능), wait()후 signal()를 하지 않으면 교착 상태 발생 가능
  - 구성 요소
    - 카운터 변수: 현재 사용 가능한 자원의 개수
    - 자원 하나 사용: 카운터 - 1(wait)
    - 자원 하나 반환: 카운터 + 1(signal)
- 모니터(Monitor)
  - 세마포의 문제를 해결하기 위해 등장한 기법, 공유 자원에 대한 접근을 감시하고 통제하는 장치
  - 내부에 락(mutex)과 조건 변수(condition variable)를 포함하여 상호 배제와 협업 조건을 모두 처리할 수 있게 해 줌
  - 구성 요소
    - 상호 배제용 락 -> 뮤텍스와 동일한 역할
    - 조건 변수 -> wait(), notify()로 협업 제어
    - 공유 자원 -> 모니터 내부에서만 접근 가능
- 데드락
  - 동기화 기법을 제대로 사용하지 않으면 교착 상태가 발생할 수 있음 -> 서로 양보하지 않고 자원을 기다리는 상황이 발생할 수 있음
  - 왜 데드락을 알아야 할까?
    - 동기화는 꼭 필요하지만 -> 락은 잠그면 반드시 다시 풀어야함, 풀지 않으면 시스템이 멈춤
    - 잘못된 설계는 치명적 -> 락을 서로 기다리면 무한 대기 발생
    - 실무에서 흔하게 발생 -> DB락, 자바 synchronized, 네트워크 대기 등
    - 원인 이해 없이 디버깅 어려움 -> 스레드 상태를 아무리 봐도 왜 안도는지 모를 수 있음
  - 데드락 발생 조건(데드락이 발생하기 위해서는 네 가지 조건이 모두 만족해야함)
    - 상호 배제(mutual exclusion)
      - 자원은 한 번에 하나의 프로세스만 사용할 수 있어야함
      - 공유 자원은 동시에 여러 프로세스가 사용할 수 없음
      - 즉, 임계 구역 보호를 위해 필수 조건
    - 점유와 대기(hold and wait)
      - 자원을 점유한 상태에서, 다른 자원을 추가로 요청하며 대기하는 상태가 존재함
      - 프로세스가 이미 자원 A는 가지고 있으면서, 자원 B가 비워지기를 기다리고 있음
    - 비선점(no preemption)
      - 다른 프로세스가 점유 중인 자원을 강제로 빼앗을 수 없음
      - 한 프로세스가 자원을 가지고 있으면 -> 운영체제가 그 자원을 강제로 회수할 수 없음
      - 자원은 반드시 자발적으로 반환되어야 함
    - 원형 대기(circular wait)
      - 프로세스들이 원형으로 자원을 기다리는 구조가 존재함
      - P1 -> P2 -> P3 -> P1
      - 자원 요청이 서로 고리처럼 엮여 있음
      - 이 고리가 끊어지지 않으면 -> 모두 영원히 대기
- 데드락 해결 및 예방 방법: 방지(prevention), 회피(avoidance), 탐지 & 회복(detection & recovery)
  - 데드락 방지
    - 데드락 발생 조건 4가지 중 최소 하나를 깨버리는 방식(앞서 본 네 가지 조건 상호배제, 점유와 대기, 비선점, 원형대기)
    - 이 중 하나라도 의도적으로 무효화하면 데드락은 절대 발생할 수 없음(발생하지 않음)
    - 조건별 방지 방법
      - 상호 배제 -> 모든 자원을 공유 자원으로 만들기 -> 이론상 가능, 현실적으론 불가능
      - 점유와 대기 -> 요청 전에 모두 할당 -> 모든 자원을 한 번에 요청? 효율이 좋지 않음
      - 비선점 -> 강제 회수를 허용 -> 다른 프로세스의 자원을 회수 가능하게? 구현이 복잡함
      - 원형 대기 -> 락 순서 고정(lock ordering) -> 항상 낮은 번호에서 높은 번호순으로 락 획득
  - 데드락 회피
    - 데드락이 발생하지 않는 안전한 경로로만 실행되도록 미리 시뮬레이션하고 자원 할당을 조절하는 방식
    - 대표 기법으로는 은행가 알고리즘(Banker's Algorithm)이 있음
      - 프로세스마다 최대 자원 요구량을 미리 등록
      - 현재 가용 자원을 고려하여 할당해줘도 시스템이 안전한 상태로 유지되는지를 계산
      - 자원 사용이 동적으로 변할 경우 어렵고 비효율적임
  - 데드락 검출 & 회복
    - 데드락을 허용하고 발생한 후 감지하고 복구하는 방식
    - 탐지 방법
      - 자원 할당 그래프를 활용
      - 주기적으로 사이클을 검사 -> 사이클이 있으면 데드락 존재
    - 회복 방법
      - 프로세스 강제 종료 -> 데드락에 걸린 프로세스 중 하나를 종료
      - 자원 선점 회수 -> 자원을 일부 회수하고 대기 중인 프로세스를 재시작
      - 운영체제가 직접 개입해서 데드락 상황을 깨뜨림

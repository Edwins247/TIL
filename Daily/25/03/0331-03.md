## TIL

## 운영체제

### 운영체제란(Operation System)?
- Computer System의 구성
  - Hardware : 컴퓨터의 자원, CPU, Memory, I/O Devices
  - Operating System : 다양한 응용 프로그램과 다중 사용자를 지원하기 위해 하드웨어를 관리하고 통제하는 프로그램
  - Applications(Application Program, 응용 프로그램) : OS와 관련되지 않은 나머지 모든 프로그램
  - Users: 사람, 다른 컴퓨터 등

- 운영체제란? 다양한 응용 프로그램과 다중 사용자를 지원하기 위해 하드웨어를 관리하는 프로그램(Software)
  - 하드웨어를 관리하기 위한 소프트웨어
  - 사용자와 하드웨어 사이의 인터페이스
  - 사용자가 프로그램을 효율적이고 편리하게 사용할 수 있도록 환경을 제공함
- 예) Windows, Mac, Linux, ...
- 운영 체제의 역할
  1. 자원 관리자(Resource Allocator)
    - 모든 자원(==HW)을 효율적으로 관리한다.
      - 자원 : CPU Time, 메모리, 파일 공간 등
    - 공정하고 효율적으로 자원을 할당한다.
      - 응용 프로그램의 요청이 충돌할 때, 어떤 프로세스에 자원을 어떻게 할당할지 효율적이고 공정한 기준으로 판단함
  2. 응용 프로그램 제어(Control Program)
    - 응용 프로그램을 실행시키고, 제어한다.
      - Process의 Lifecycle(생성부터 종료까지) 관리
    - 컴퓨터의 오류나 부적절한 사용을 방지

### 커널 모드와 유저 모드
- Software의 종류 : 모든 소프트웨어는 System Software와 Application Software 둘 중 하나에 속함
  - Application Software : OS와 관련되지 않은 나머지 모든 프로그램
  - System Software: OS와 관련된 프로그램이지만, Kernel에 꼭 필요한 것은 아닌 것
    - Operation System : Kernel

- 커널(Kernel)이란?
  - OS의 핵심 구성 요소
  - 하드웨어와 응용 프로그램을 매개하는 핵심 인터페이스
  - 컴퓨터에 항상 실행되고 있는 유일한 프로그램
  - 좁은 의미로, OS == Kernel Program이라고 할 수 있음
  - 커널은 사용자가 볼 수 없으며, 작업을 위한 별도의 메모리 공간(커널 공간)이 있음(사용자 공간과 대비되는 개념)

- 커널의 기능 -> OS 기능
  1. 메모리 관리 : 메모리가 어디에서 무엇을 저장하는 데 얼마나 사용되는지 추적
  2. 프로세스 관리 : 어느 프로세스가 CPU를 언제 사용할지, 얼마나 사용할지 결정
  3. 장치 드라이버 : 하드웨어와 프로세스 사이에서 중재자 역할
  4. 시스템 콜 및 보안 : 프로세스의 서비스 요청을 수신

- 커널 모드와 유저 모드
  - OS는 두가지 모드가 있음 : 시스템을 응용 프로그램의 잘못된 접근으로부터 보호하기 위해, 컴퓨터 시스템에 크리티컬한 영향을 주지 못하도록 방지함
  - Mode bit: 현재 모드를 HW적으로 저장하는 Bit 0 = kernel mode, 1 = user mode
  - Privileged Instructions는 오직 커널 모드에서만 수행 가능함

- System Call
  - 운영체제의 커널이 제공하는 서비스에 대해, 응용 프로그램의 요청에 따라 커널에 접근하기 위한 인터페이스
  - 고급 언어(C, Java, ...)로 작성된 프로그램은 직접 시스템콜을 호출할 수 없으며, 언어별로 API를 통해 시스템콜 함수를 호출하게 되어 있음
  - 시스템콜의 실제 동작은 커널모드에서 실행됨
  - 시스템 콜 유형 : 프로세스 제어(생성, Kill), 파일 조작, I/O Device 제어 등
  - 예 : open(), close(), read(), write(), fork(), exec()

- Interrupt
  - 끼어듦, 가로막기
  - CPU가 프로그램을 실행하고 있을 떄, I/O 장치 등에 예외상황이 발생하여 처리가 필요할 경우, CPU에게 알려 처리할 수 있도록 요청하는 것
  - Polling과 반대되는 개념
  - CPU는 인터럽트를 감지하면 실행중인 코드를 중단하고 해당 인터럽트를 위한 처리 프로그램으로 점프하여 해당 작업을 수행함
  - Interrupt Vector(Table)에 각 Device Code별로 ISR의 시작 주소가 저장되어 있음
    - ISR(Interrupt Service Routine) : 인터럽트 처리를 위한 루틴, 각 인터럽트마다 어떤 동작을 해서 처리해야 하는지 정의되어 있음
  - 참고) 하드웨어 인터럽트, 소프트웨어 인터럽트, 예외(Exception), 시스템 콜

- 동작 예시
  1. 유저 모드로 사용자 프로그램이 실행된다.
  2. 실행 도중에 사용자 프로그램이 I/O 연산을 수행하고자 한다면 -> I/O 관련 시스템콜을 호출한다.
  3. 시스템 콜이 호출되면 유저모드 -> 커널모드로 변환한 후, 커널모드에서 시스템콜이 실행된다(실제 I/O 수행)
  4. 다시 유저모드로 돌아가 프로그램 실행을 계속 진행한다.
- 요약 : 유저 모드 -> 시스템 콜 -> 커널 모드 -> Privileged Instruction 수행 -> 다시 유저 모드

### 쉘과 터미널
- Shell이란
  - 사용자가 운영체제를 조작할 수 있도록 인터페이스를 제공하는 응용 프로그램
    - OS와 User 사이의 Interface
    - 명령을 해석하고, 명령을 수행하고, 그 결과를 사용자에게 출력해줌
- 쉘의 종류는 CLI(Command Line Interface), GUI(Graphics User Interface) 두 가지임
  - 리눅스 환경은 대부분 GUI를 제공하지 않음
- 대표적인 Shell : 리눅스 bash, sh, zsh...
- 터미널 : Shell을 실행할 수 있는 실행 환경
  - Text로 입력을 받아서, Output을 Text로 보여줌
  - Windows: 파워쉘, WSL(Window Subsystem for Linux)
  - Linux, Mac : Terminal, Iterm
- CLI : Windows의 Power Shell / Mac의 Terminal
- GUI : Windows의 탐색기 / Mac의 Finder

### Process
- Process란?
  - 실행중인 프로그램. A program in execution
    - 프로그램은 생명이 없음. Disk에 저장되어 실행을 기다리는 단순 파일
  - Process는 OS로부터 자원을 할당받아야만 실행될 수 있음
    - 자원 : CPU time, Memory, 파일, I/O Device
  - 참고) 스케줄링의 대상이라는 의미로, job, task 등의 용어로도 불림
  - OS는 Process와 Thread 관리의 책임이 있음
    - 프로세스간 통신, 동기화, 데드락 관리 등

- 프로세스의 State(라이프사이클)
  - New: 프로세스가 생성된 상태
  - Ready: 프로세스가 CPU를 할당받기를 대기하고 있는 상태(메모리상에 주소공간이 할당된 상태)
  - Running : 명령어(Instruction)가 실행되고 있는 상태
  - Waiting(Blocked) : 프로세스가 특정 이벤트가 발생하기까지 기다리고 있는 상태
    - 예) I/O 연산의 완료, Mutex/Semaphore 등 Signal의 수신
  - Terminated: 프로세스의 실행이 완료된 상태

- 주소 공간(Address Space) - 프로세스를 위한 메모리 구조
  - Process가 CPU를 할당 받으면, 각 프로세스별로 메모리에 주소 공간이 할당되어 ready 상태가 됨
  1) Text(Code) : 프로그램의 소스코드(같은 프로그램이라면 이 Text 영역이 같음)
  2) Data: 전역변수
  3) Stack : 지역변수, 파라미터, Return Address
  4) Heap : 프로그램 실행중에 동적으로 할당된 메모리 (예 - C언어의 malloc(), OOP 언어의 객체)
  - 재귀 호출의 깊이가 깊어지면, 각 프로세스별 Stack 공간이 한정적이기 때문에 Stack Overflow가 발생함
  - 참고) Java의 Garbage Collection
- PC란? Program Counter. 다음 실행할 명령의 주소를 갖고있는 포인터
- SP란? Stack Pointer. 스택의 Top의 주소를 갖고 있음

- PCB
  - Process Control Block
  - 프로세스에 대한 정보를 저장하고 있는 공간(자료구조). 메타데이터
  - 각 프로세스 생성과 동시에 PCB가 생성됨
  - PCB에 저장하고 있는 정보 : Process의 상태, PC, CPU 레지스터, CPU 스케줄링 정보, 메모리 관리 정보, 계정 정보, I/O 상태 정보

- Context Switching(문맥 교환)
  - CPU가 실행할 프로세스를 다른 프로세스로 전환(switch)하는 것
  - 과정
    1) Save : 이전 프로세스의 상태(PCB)를 저장함
    2) Load : 새로운 프로세스의 저장되어 있던 상태(PCB)를 불러옴
  - Context Switching에 소요되는 시간은 Overhead이다.
    - Overhead : 어떤 일을 하기 위해 부차적으로 필요한 간접적인 시간/자원
    - 시스템은 Context Switching이 일어나는 동안 아무것도 하지 못하기 때문임
    - 프로세스(스레드)의 개수가 많아질수록 Context Switching이 빈번하게 발생하며, Overhead가 커짐

### IPC
- IPC란?
  - Inter-Process Communication
  - 즉, 프로세스간의 통신
- 왜 필요한가?
  - 프로세스는 서로 독립적으로 실행됨
  - 메모리 영역(주소 공간)이 분리되어 있으므로, 프로세스간 통신을 위한 별도의 방법이 필요함
  - 예) 데이터 읽고 쓰기, 프로세스의 상태 확인 등
- IPC 기법
  - 공유 메모리 : 커널 영역에 메모리 공간을 만들고 공유해서 활용하는 방식
  - 메세지 큐
  - PIPE
    - 단방향
    - 양방향
  - 파일, 데이터베이스 등 외부 스토리지 활용

### Thread
- Thread란?
  - 프로세스 안에서의 실행의 단위
  - Light Weight Process
  - 프로세스마다 최소 1개의 스레드(메인 스레드)가 있음
  - 운영 체제는 하나의 프로세스에 대해 다중 스레드를 지원함
    - 여러개의 스레드가 병렬로 실행될 수 있음. 따라서 멀티 코어인 경우 특히 좋음
- Process와 Thread의 차이점 : 자원의 공유
  - Process는 각자 자신만의 독립적인 메모리(주소공간)을 가짐
  - Thread는 자신만의 Stack만 할당 받고, 나머지 영역인 Code/Data/Heap은 다른 스레드와 자원을 공유함
    - 자신만의 PC, 레지스터도 있음
   
- 멀티 프로세싱과 멀티 스레딩
  - 멀티 프로세싱 : 프로세서 == CPU. 여러개의 프로세서를 사용하는 것
    - 장점 : 안정성/신뢰성이 좋음
      - 서로 독립적으로 처리되므로, 특정 프로세스에 문제가 발생하더라도 다른 프로세서로 처리 가능
    - 단점 : (상대적으로) 많은 메모리, CPU Time, Context Switching의 Overhead.
  - 멀티 스레딩 : 스레드를 여러개 사용하는 것
    - 장점 : 메모리 공유 -> 자원 절약, 스레드끼리 통신이(상대적으로) 쉬움, 스레드간 전환(Context Switching) 속도도 빠름. 구현도 쉬움
    - 단점
      - 자원 간 동기화 문제
      - 안정성(한 스레드에 문제가 발생하면 프로세스 전체 동작에 영향을 줌)
      - 실행 순서가 보장되지 않음

### 동기화
- Critical Section : 공유 자원에 접근하는 부분(코드)
- 동기화 이슈 : 여러 프로세스(스레드)가 동시에 같은 공유 자원에 접근하여, Read/Write를 할 떄 영향을 주고 오동작을 야기하는 것
- 동기화를 해결할 수 있는 대표적인 방법은 Mutex와 Semaphore가 있음
- Mutex
  - Mutual Exclusion의 약어. 상호 배제
  - Critical Section에는 단 하나의 프로세스(스레드)만 접근할 수 있어야 함
  - 동작 원리
    - Lock 연산 : Critical Section에 들어갈 때, 다른 스레드가 접근 못하도록 Lock을 걸고 들어감
    - Unlock 연산 : 자원을 다 사용하고 나면, 다른 스레드가 사용할 수 있도록 Lock을 해제함
- Semaphore
  - S = 사용 가능한 자원의 개수로 초기화(S는 정수)
    - 자원을 사용하면, S값 1 감소
    - 자원을 놔주면, S값 1 증가
  - 동작 원리 : 2개의 Atomic한 연산을 통해 수행
    - Wait 연산 : Critical Section에 들어가기 전에, 자원을 사용할 수 있는지 판단하고, S를 1 감소시키고 들어감
    - Signal 연산 : Critical Section에서 나올 때, S를 1 증가시키고 반납했음을 대기중인 프로세스에게 알림(Signal을 보냄)
  - Mutex는 이진 세마포(Binary Semaphore)임
- 참고) 프로그래밍 언어별 멀티 스레드 및 동기화 적용 예시(Java는 멀티 스레드, JS는 싱글 스레드)

### 데드락
- Deadlock(교착 상태)이란
  - 두 개 이상의 프로세스가 서로 원하는 자원이 상대 프로세스에게 할당되어 있어서, 무한 대기 상태에 빠져 다음 처리르 못하는 상태
- 데드락 발생 조건 4가지
  - 아래 조건 4가지가 모두 성립해야 데드락이 발생함
  1) Mutual Exclusion(상호 배제) : 자원은 한번에 한개에 프로세스만 사용할 수 있음
  2) Hold and wait(점유 및 대기) : 최소 하나의 자원을 점유하고 있으면서, 다른 프로세스에 할당되어 사용중인 자원을 추가로 점유하기 위해 대기하는 프로세스가 존재함
  3) No Preemption(비선점) : 다른 프로세스에게 할당된 자원은 사용이 끝날 때까지 강제로 빼앗을 수 없음
  4) Circular Wait(순환 대기) : 프로세스의 집합에서 순환 형태로 자원을 대기하고 있어야 함
- 데드락의 처리 방법
  - 예방(Prevention) 및 회피(Avoidance) : 위 4가지 중 하나라도 성립하지 않게 한다면 데드락 문제를 해결할 수 있음
  - 탐지(Detection) 및 회복(Recovery) : 교착상태가 되도록 허용된 조건에서, 교착상태를 탐지한 후 회복시키는 방법

### 스케줄링
- 스케줄링이란 : 프로세스의 실행 순서를 관리하여 CPU를 효율적으로 사용하기 위한 정책
  - 프로세스가 작업을 수행하려면, 스케줄러로부터 CPU를 할당 받아야만 함
  - CPU가 놀고 있으면, OS는 다음으로 실행할 프로세스(CPU를 할당받을 프로세스)를 선택해야함
- 스케줄링의 목적
  - Keep CPU as busy as possible
  - 공정하게 CPU를 할당
  - 최소한의 대기 시간/지연 시간
  - 최대한의 처리량(Throughput)
- 참고) Starvation(기아 상태)
  - 우선순위가 낮은 프로세스가 원하는 자원을 계속(영원히, never!) 할당받지 못하고 있는 상태
  - 그 프로세스의 우선순위가 낮아서 발생함 -> 우선순위를 강제로 높여줘서 해결 가능(Aging)

- 스케줄링 알고리즘 : 다음으로 실행할 프로세스를 결정하는 방법
  - 비선점(Non-Preemptive) : 실행중인 상태의 프로세스가 종료되어 자원을 반납해야만, 다른 프로세스가 자원을 사용할 수 있음
    - FCFS : First Come First Serve, 먼저 온 프로세스부터 처리. 가장 단순한 방법(FIFO 큐 활용)
    - SJF : Shortest Job First, 가장 실행 시간이 작은 프로세스를 우선 선택
  - 선점 스케줄링(Preemptive) : 실행중인 상태의 프로세스가 종료되기 전에, 강제로 CPU를 회수하고 다른 프로세스가 사용할 수 있도록 할 수 있음
    - RR(Round Robin) : 계속 돌아가면서 일정 주기동안 공평하게 사용(Time Sharing)
    - Priority Scheduling : 정해진 우선순위에 따라, 우선순위가 높은 프로세스부터 실행

### 가상 메모리
- 가상 메모리의 필요성
  - 하나의 컴퓨터에는 여러 개의 프로세스가 실행됨
  - 프로세스가 실행되기 위해서는 자원(CPU와 메모리)를 할당받아야 함
  - 그러나, 메모리(RAM)의 크기에는 한계가 있음 : 8GB, 16GB, 32GB,...
  - 모든 프로세스를 (물리) 메모리에 할당하기에는 메모리가 부족함
  - 예) 게임 하나만 켜도 램 4GB, 우리는 메신저도 켜고, 웹 브라우저도 켜고, 음악도 듣고, 각종 사용자 어플리케이션을 동시에 띄워놓고 컴퓨터를 사용함 -> 어떻게 가능할까? -> 가상 메모리! + a
    - 참고)리눅스의 Swap Memory

- 가상 메모리(Virtual Memory)란? 메모리 관리 기법 중 하나로, 실제로는 한계가 있는 물리 메모리(Physical Memory)를 추상화하여 매우 큰 메모리로 보이도록 하는 기법
  - 즉, 물리 메모리와 가상 메모리의 개념을 분리하여 메모리를 관리하고자 하는 기법
  - 각 프로세스마다 물리 메모리 주소가 아닌 가상의 메모리 주소를 부여하는 것
    - 물리 메모리 주소 : Physicla Address, Real Address(실제 메모리 주소)
    - 가상 메모리 주소 : Virtual Address, Logical Address(추상화시킨 논리적 주소)
  - 프로세스와 CPU는 가상 주소를 참조하고 있어서, OS와 요청을 주고 받을 때 가상 메모리 주소로 소통함
- 가상 주소와 물리 주소 사이의 변환은 어떻게? MMU가 담당함
  - MMU(Memory Management Unit) : 가상 메모리 주소를 실제 메모리 주소로 변환해주는 하드웨어 부분
    - 참고) TLB: MMU가 페이지 변환 정보를 빠르게 얻어오기 위해 참조하는 버퍼, 일종의 캐시
  - 프로세스가 실행되면서, CPU가 메모리에 접근할 필요가 있으면, 직접 실제 주소를 계산하는 것이 아니라 MMU의 도움을 받음
  - 사용자(Program을 개발하고 실행시키는 주체)는 실제 주소를 알 필요가 없고, 가상 메모리만 알고있어도 됨

- 가상 메모리를 구현하는 방식은 크게 2가지
  1. Paging
  2. Segmentation
  - 둘의 차이?
    - 메모리를 쪼개는 크기 : 동일한 고정 크기 vs 가변 크기
    - 참고) 외부 단편화(Paging으로 해결 가능)와 내부 단편화(Segmentation으로 해결 가능)
- Paging: 프로세스를 고정 크기인 Page 단위로 잘라서 관리하는 메모리 관리 기법
  - Page: 가상 메모리를 일정한 크기로 나눈 블록
  - Frame: 물리 메모리를 일정한 크키로 나눈 블록
  - Page Table : 각 프로세스마다 페이지 변환 정보가 저장되어 있는 자료구조
  - Page(가상 메모리 공간)가 하나의 Frame(물리 메모리 공간)을 할당 받아야만 물리 메모리에 위치하게 됨
  - 아직 Frame을 할당받지 못한 Page들은 보조기억장치(Disk, 느림)에 저장되어 있음

- Demand Paging(요구 페이징)
  - Demand Paging이란
    - 프로그램 실행 과정에서 '요구되는 Page만' 메모리에 올리는 전략
    - 즉, 한번도 접근되지 않은 Page는 물리 메모리(Frame)에 올라가지 않음
    - 동작 과정
      - 어떤 프로세스가 참조하고 있는 페이지가 Frame을 할당 받았는지(Page Table에 있는지) 확인
      - 있으면, 빠르게 메모리에 접근해서 가져다 씀
      - 없으면, 그 페이지를 보조기억장치(Disk)에서 읽어와서 물리 메모리에 올리고(Frame 할당), Page Table에 저장하고 갱신함
  - Demand Paging의 성능을 높이기 위해서는 Page Fault 발생률을 최소한으로 줄여야함
    - Page Fault란? 마치 Cache의 Miss와 같은 개념. 해당 페이지가 메모리에 없는 경우!
      - Page Fault가 발생하면 Disk까지 찾아가서 프로세스의 페이지를 메모리에 올리고 -> Page 테이블을 갱신하게 된다 -> 고비용
  - Page Fault를 줄이기 위해 다양한 Page Replacement(페이지 교체) 알고리즘이 있음
    - FIFO, LRU, LFU, Priority, Optimal(예측 불가능)
    - 캐시 교체 알고리즘과 거의 유사함
  - 참고) Trashing: 반복적으로 Page Fault가 발생해서, Page 교체 작업이 과도하게 발생해 실제로 아무런 일을 수행하지 못하는 상황      
